{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atomwalk12/Dropbox (Old)/notes/vision/project/BeyondVisionQA/model.py:128: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  self.metric = load_metric(\"bertscore\")\n",
      "/home/atomwalk12/anaconda3/envs/questllama/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for bertscore contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/bertscore/bertscore.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5548302cc26a4e9f91861b18daf8e80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52341473e91442cbb24e04d7d44b2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from qadataset import QADataset\n",
    "from config import dataset_config, model_config\n",
    "\n",
    "MODEL_ID = \"Salesforce/blip2-opt-2.7b\"\n",
    "\n",
    "\n",
    "train_dataset = QADataset(dataset_config, split=\"train[:100]\")\n",
    "val_dataset = QADataset(dataset_config, split=\"train[:10]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20cf2c4833b43938633429c800fa444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "## Load model\n",
    "\n",
    "# Three options for training, from the lowest precision training to the highest precision training:\n",
    "# - QLora\n",
    "# - Standard Lora\n",
    "# - Full fine-tuning\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from trainer_blip2 import BLIP2ModelPLModule\n",
    "from trainer_blip2 import BLIP2PLModule\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=\"all-linear\",\n",
    "    init_lora_weights=\"gaussian\",\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_epochs': 20, 'warmup_epochs': 1.67, 'check_val_every_n_epoch': 1, 'gradient_clip_val': 1.0, 'accumulate_grad_batches': 8, 'lr': 0.0005, 'batch_size': 9, 'seed': 1337, 'num_nodes': 1, 'result_path': './result', 'verbose': True, 'betas': [0.9, 0.999], 'weight_decay': 0.05, 'max_length': 256}\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from config import dataset_config\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from config import metrics\n",
    "from transformers import AutoProcessor\n",
    "from dataset_configs.easy_vqa import translate\n",
    "from transformers import AutoProcessor\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "processor.tokenizer.padding_side = \"right\" # during training, one always uses padding on the right\n",
    "\n",
    "class BLIP2ModelPLModule(L.LightningModule):\n",
    "    def __init__(self, hyperparameters, model, train_dataset, val_dataset):\n",
    "        super().__init__()\n",
    "        self.hyperparams = hyperparameters\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "        self.batch_size = hyperparameters.get(\"batch_size\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        inputs, labels = batch\n",
    "\n",
    "        outputs = self.model(**inputs,\n",
    "                            labels=labels)\n",
    "        loss = outputs.loss\n",
    "        print(f\"Epoch {self.current_epoch}, loss: {loss.item()}\")\n",
    "\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
    "\n",
    "        inputs, answers = batch\n",
    "\n",
    "        # auto-regressively generate token IDs\n",
    "\n",
    "        \n",
    "        generated_ids = self.model.generate(**inputs)\n",
    "        # turn them back into text, chopping of the prompt\n",
    "        # important: we don't skip special tokens here, because we want to see them in the output\n",
    "        predictions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        print(f\"==================Dataset batch: {batch_idx}/{self.val_dataset.dataset_length // self.batch_size}==================\")\n",
    "        scores = []\n",
    "        i = 0\n",
    "        for pred, answer in zip(predictions, answers):\n",
    "            print(f\"Question: {self.val_dataset.dataset[batch_idx*self.batch_size+i]['question']}\")\n",
    "            print(f\"Prediction: {pred}\")\n",
    "            print(f\"Answer: {answer}\")\n",
    "            i += 1\n",
    "\n",
    "        for metric in metrics:\n",
    "            scores = metric.compute(predictions=predictions, references=answers, model=self)\n",
    "            \n",
    "        return scores\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print(self.hyperparams)\n",
    "        print(\"Applying both Adam and Cosine Scheduler Warmup\")\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hyperparams[\"lr\"],\n",
    "            betas=self.hyperparams['betas'],\n",
    "            weight_decay=self.hyperparams['weight_decay']\n",
    "        )\n",
    "\n",
    "        # Calculate total steps based on epochs and batch size\n",
    "        total_epochs = self.hyperparams['max_epochs']\n",
    "        dataset_size = len(self.train_dataset)  # Assuming you have access to the dataset size\n",
    "        batch_size = self.hyperparams['batch_size']\n",
    "        steps_per_epoch = dataset_size // batch_size  # Integer division\n",
    "        total_steps = total_epochs * steps_per_epoch\n",
    "\n",
    "\n",
    "        # Convert warmup steps to warmup epochs if necessary\n",
    "        warmup_epochs = self.hyperparams['warmup_epochs']\n",
    "        warmup_steps = math.ceil(warmup_epochs * steps_per_epoch)\n",
    "        \n",
    "        print(f\"Running warmup for a total of {warmup_steps} steps\")\n",
    "\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "    \n",
    "        return [optimizer], [scheduler]\n",
    "        \n",
    "\n",
    "\n",
    "class BLIP2PLModule(BLIP2ModelPLModule):\n",
    "    \n",
    "    def __init__(self, config, model, train_dataset, val_dataset):\n",
    "        super().__init__(config, model, train_dataset, val_dataset)\n",
    "    \n",
    "    def train_numeric_labels(examples):\n",
    "        images = []\n",
    "        texts = []\n",
    "        batch_labels = []\n",
    "        for example in examples:\n",
    "            image, ground_truth = example\n",
    "            input, label = translate(ground_truth, training=True)\n",
    "            \n",
    "            images.append(image)\n",
    "            texts.append(input)\n",
    "            batch_labels.append({ 'label_ids': label['label_ids'], 'scores': torch.from_numpy(label['scores'])})\n",
    "\n",
    "        # inputs = processor(images=images, text=texts, return_tensors=\"pt\").to(device=\"cuda\", dtype=torch.float16)\n",
    "        inputs = processor(text=texts, images=images, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        result = []\n",
    "\n",
    "        for label in batch_labels:\n",
    "            scores = label['scores']\n",
    "            result.append(scores)\n",
    "        \n",
    "        return inputs, torch.stack(result)\n",
    "\n",
    "\n",
    "    \n",
    "    def train_textual_labels(examples):\n",
    "        images = []\n",
    "        texts = []\n",
    "        for example in examples:\n",
    "            image, ground_truth = example\n",
    "            input = translate(ground_truth, training=True)\n",
    "            \n",
    "            images.append(image)\n",
    "            texts.append(input)    \n",
    "\n",
    "        # inputs = processor(images=images, text=texts, return_tensors=\"pt\").to(device=\"cuda\", dtype=torch.float16)\n",
    "        inputs = processor(text=texts, images=images, padding=True, return_tensors=\"pt\")\n",
    "        \n",
    "        labels = inputs[\"input_ids\"].clone()\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def eval_numeric_labels(examples):\n",
    "        images = []\n",
    "        texts = []\n",
    "        answers = []\n",
    "        for example in examples:\n",
    "            image, ground_truth = example\n",
    "            input, output = translate(ground_truth, training=False)\n",
    "            \n",
    "            images.append(image)\n",
    "            texts.append(input) \n",
    "            answers.append(output)\n",
    "\n",
    "        inputs = processor(text=texts, images=images, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "        return inputs, answers\n",
    "    \n",
    "    def eval_textual_labels(examples):\n",
    "        images = []\n",
    "        texts = []\n",
    "        answers = []\n",
    "        for example in examples:\n",
    "            image, ground_truth = example\n",
    "            input, output = translate(ground_truth, training=False)\n",
    "            \n",
    "            images.append(image)\n",
    "            texts.append(input) \n",
    "            answers.append(output)\n",
    "\n",
    "        inputs = processor(text=texts, images=images, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "        return inputs, answers\n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        if model_config['classification']:\n",
    "            return DataLoader(self.train_dataset, collate_fn=BLIP2PLModule.train_numeric_labels, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "        else:\n",
    "            return DataLoader(self.train_dataset, collate_fn=BLIP2PLModule.train_textual_labels, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if model_config['classification']:\n",
    "            return DataLoader(self.val_dataset, collate_fn=BLIP2PLModule.eval_numeric_labels, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
    "        else:\n",
    "            return DataLoader(self.val_dataset, collate_fn=BLIP2PLModule.eval_textual_labels, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"max_epochs\": 10,\n",
    "          # \"val_check_interval\": 0.2, # how many times we want to validate during an epoch\n",
    "          \"check_val_every_n_epoch\": 1,\n",
    "          \"gradient_clip_val\": 1.0,\n",
    "          \"accumulate_grad_batches\": 8,\n",
    "          \"lr\": 1e-4,\n",
    "          \"batch_size\": 8,\n",
    "          \"seed\":2022,\n",
    "          \"num_nodes\": 1,\n",
    "          \"warmup_steps\": 50,\n",
    "          \"result_path\": \"./result\",\n",
    "          \"verbose\": True,\n",
    "          \"betas\": [0.9, 0.999],\n",
    "          \"weight_decay\": 0.05,\n",
    "          \"warmup_epochs\": 1.67\n",
    "}\n",
    "\n",
    "model_module = BLIP2PLModule(config, model, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | model | PeftModel | 2.0 B  | train\n",
      "--------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "1.9 B     Non-trainable params\n",
      "2.0 B     Total params\n",
      "7,848.709 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_epochs': 10, 'check_val_every_n_epoch': 1, 'gradient_clip_val': 1.0, 'accumulate_grad_batches': 8, 'lr': 0.0001, 'batch_size': 8, 'seed': 2022, 'num_nodes': 1, 'warmup_steps': 50, 'result_path': './result', 'verbose': True, 'betas': [0.9, 0.999], 'weight_decay': 0.05, 'warmup_epochs': 1.67}\n",
      "Applying both Adam and Cosine Scheduler Warmup\n",
      "Running warmup for a total of 21 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atomwalk12/anaconda3/envs/questllama/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9aa0a555bfb487aa402812d3a83ce78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 6.892815589904785\n",
      "Epoch 0, loss: 5.4359450340271\n",
      "Epoch 0, loss: 5.316230773925781\n",
      "Epoch 0, loss: 5.43276309967041\n",
      "Epoch 0, loss: 5.11403226852417\n",
      "Epoch 0, loss: 5.167695045471191\n",
      "Epoch 0, loss: 4.661338806152344\n",
      "Epoch 0, loss: 6.000909805297852\n",
      "Epoch 0, loss: 5.396512985229492\n",
      "Epoch 0, loss: 6.1636834144592285\n",
      "Epoch 0, loss: 5.4258713722229\n",
      "Epoch 0, loss: 5.397549629211426\n",
      "Epoch 0, loss: 6.563390731811523\n",
      "Epoch 1, loss: 5.582911968231201\n",
      "Epoch 1, loss: 5.481412410736084\n",
      "Epoch 1, loss: 6.351603984832764\n",
      "Epoch 1, loss: 5.664048194885254\n",
      "Epoch 1, loss: 5.333680152893066\n",
      "Epoch 1, loss: 6.311262607574463\n",
      "Epoch 1, loss: 6.03288459777832\n",
      "Epoch 1, loss: 4.8487467765808105\n",
      "Epoch 1, loss: 5.587518215179443\n",
      "Epoch 1, loss: 6.099411964416504\n",
      "Epoch 1, loss: 5.3607869148254395\n",
      "Epoch 1, loss: 5.456619739532471\n",
      "Epoch 1, loss: 4.6082282066345215\n",
      "Epoch 2, loss: 6.109043121337891\n",
      "Epoch 2, loss: 5.265809059143066\n",
      "Epoch 2, loss: 5.383036136627197\n",
      "Epoch 2, loss: 6.344324111938477\n",
      "Epoch 2, loss: 4.8129801750183105\n",
      "Epoch 2, loss: 4.535933494567871\n",
      "Epoch 2, loss: 5.376427173614502\n",
      "Epoch 2, loss: 4.83123254776001\n",
      "Epoch 2, loss: 5.050971508026123\n",
      "Epoch 2, loss: 5.891811370849609\n",
      "Epoch 2, loss: 4.818905353546143\n",
      "Epoch 2, loss: 6.05479621887207\n",
      "Epoch 2, loss: 4.346171855926514\n",
      "Epoch 3, loss: 4.159526348114014\n",
      "Epoch 3, loss: 4.680662155151367\n",
      "Epoch 3, loss: 5.110794544219971\n",
      "Epoch 3, loss: 5.616490364074707\n",
      "Epoch 3, loss: 5.441620826721191\n",
      "Epoch 3, loss: 5.651975631713867\n",
      "Epoch 3, loss: 5.448392868041992\n",
      "Epoch 3, loss: 5.062097072601318\n",
      "Epoch 3, loss: 5.290004730224609\n",
      "Epoch 3, loss: 4.333127021789551\n",
      "Epoch 3, loss: 4.642219543457031\n",
      "Epoch 3, loss: 4.914428234100342\n",
      "Epoch 3, loss: 4.527565956115723\n",
      "Epoch 4, loss: 5.820257663726807\n",
      "Epoch 4, loss: 3.392204999923706\n",
      "Epoch 4, loss: 4.454659461975098\n",
      "Epoch 4, loss: 4.730099201202393\n",
      "Epoch 4, loss: 5.66209077835083\n",
      "Epoch 4, loss: 4.972411632537842\n",
      "Epoch 4, loss: 5.276112079620361\n",
      "Epoch 4, loss: 4.234918594360352\n",
      "Epoch 4, loss: 4.095731258392334\n",
      "Epoch 4, loss: 4.342704772949219\n",
      "Epoch 4, loss: 4.5469970703125\n",
      "Epoch 4, loss: 4.387345314025879\n",
      "Epoch 4, loss: 3.716590642929077\n",
      "Epoch 5, loss: 4.704527854919434\n",
      "Epoch 5, loss: 5.116504192352295\n",
      "Epoch 5, loss: 3.9929885864257812\n",
      "Epoch 5, loss: 3.2135422229766846\n",
      "Epoch 5, loss: 4.699431896209717\n",
      "Epoch 5, loss: 3.391407012939453\n",
      "Epoch 5, loss: 4.942661285400391\n",
      "Epoch 5, loss: 4.2240400314331055\n",
      "Epoch 5, loss: 4.4207563400268555\n",
      "Epoch 5, loss: 4.4700608253479\n",
      "Epoch 5, loss: 3.9540154933929443\n",
      "Epoch 5, loss: 3.9052038192749023\n",
      "Epoch 5, loss: 3.925027370452881\n",
      "Epoch 6, loss: 3.3054184913635254\n",
      "Epoch 6, loss: 3.718641757965088\n",
      "Epoch 6, loss: 4.223984718322754\n",
      "Epoch 6, loss: 4.359201908111572\n",
      "Epoch 6, loss: 4.2917585372924805\n",
      "Epoch 6, loss: 4.150655746459961\n",
      "Epoch 6, loss: 3.5693397521972656\n",
      "Epoch 6, loss: 3.9603755474090576\n",
      "Epoch 6, loss: 3.332501173019409\n",
      "Epoch 6, loss: 3.68587589263916\n",
      "Epoch 6, loss: 3.7246785163879395\n",
      "Epoch 6, loss: 4.026719093322754\n",
      "Epoch 6, loss: 4.008050441741943\n",
      "Epoch 7, loss: 3.6745190620422363\n",
      "Epoch 7, loss: 3.805960178375244\n",
      "Epoch 7, loss: 4.202480316162109\n",
      "Epoch 7, loss: 2.6800377368927\n",
      "Epoch 7, loss: 3.4830663204193115\n",
      "Epoch 7, loss: 3.1147115230560303\n",
      "Epoch 7, loss: 3.4891927242279053\n",
      "Epoch 7, loss: 3.2651164531707764\n",
      "Epoch 7, loss: 3.4611992835998535\n",
      "Epoch 7, loss: 2.7171339988708496\n",
      "Epoch 7, loss: 3.628457546234131\n",
      "Epoch 7, loss: 2.8557510375976562\n",
      "Epoch 7, loss: 2.9263458251953125\n",
      "Epoch 8, loss: 2.915764808654785\n",
      "Epoch 8, loss: 2.9571115970611572\n",
      "Epoch 8, loss: 3.3889236450195312\n",
      "Epoch 8, loss: 2.7277886867523193\n",
      "Epoch 8, loss: 2.7662665843963623\n",
      "Epoch 8, loss: 4.026178359985352\n",
      "Epoch 8, loss: 2.6286706924438477\n",
      "Epoch 8, loss: 3.12699294090271\n",
      "Epoch 8, loss: 3.154118537902832\n",
      "Epoch 8, loss: 2.14449405670166\n",
      "Epoch 8, loss: 3.4526450634002686\n",
      "Epoch 8, loss: 3.1402692794799805\n",
      "Epoch 8, loss: 2.727452039718628\n",
      "Epoch 9, loss: 2.369853973388672\n",
      "Epoch 9, loss: 1.9748976230621338\n",
      "Epoch 9, loss: 2.1828548908233643\n",
      "Epoch 9, loss: 2.716757297515869\n",
      "Epoch 9, loss: 2.2846124172210693\n",
      "Epoch 9, loss: 2.1057446002960205\n",
      "Epoch 9, loss: 2.338505506515503\n",
      "Epoch 9, loss: 2.50600266456604\n",
      "Epoch 9, loss: 2.403193235397339\n",
      "Epoch 9, loss: 2.2039198875427246\n",
      "Epoch 9, loss: 2.676886558532715\n",
      "Epoch 9, loss: 2.8195629119873047\n",
      "Epoch 9, loss: 2.7078938484191895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b5409a43164b5face3bdea0eaa3246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 0/1==================\n",
      "Question: what is the blue shape?\n",
      "Prediction: thickness.\n",
      "\n",
      "Answer: rectangle\n",
      "Question: what color is the shape?\n",
      "Prediction: or.\n",
      "\n",
      "Answer: blue\n",
      "Question: does the image contain a rectangle?\n",
      "Prediction: alas, no.\n",
      "\n",
      "Answer: yes\n",
      "Question: is there a triangle in the image?\n",
      "Prediction: ormaybe.\n",
      "\n",
      "Answer: no\n",
      "Question: is there a black shape?\n",
      "Prediction: or is there a blue shape\n",
      "Answer: no\n",
      "Question: does the image not contain a gray shape?\n",
      "Prediction:  no.\n",
      "\n",
      "Answer: yes\n",
      "Question: is there a red shape in the image?\n",
      "Prediction:  no.\n",
      "\n",
      "Answer: no\n",
      "Question: does the image not contain a red shape?\n",
      "Prediction:  no.\n",
      "\n",
      "Answer: yes\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_bertscore_f1: 0.9095668345689774 \n",
      "\n",
      "\n",
      "==================Dataset batch: 1/1==================\n",
      "Question: is there not a blue shape?\n",
      "Prediction: . Yes.\n",
      "\n",
      "Answer: no\n",
      "Question: is there not a blue shape in the image?\n",
      "Prediction:  yes.\n",
      "\n",
      "Answer: no\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.8907240629196167 \n",
      "\n",
      "\n",
      "Epoch 10, loss: 2.3488593101501465\n",
      "Epoch 10, loss: 1.6805652379989624\n",
      "Epoch 10, loss: 2.200425148010254\n",
      "Epoch 10, loss: 2.837015151977539\n",
      "Epoch 10, loss: 2.193631172180176\n",
      "Epoch 10, loss: 2.352471351623535\n",
      "Epoch 10, loss: 1.8239896297454834\n",
      "Epoch 10, loss: 1.967983603477478\n",
      "Epoch 10, loss: 2.1162290573120117\n",
      "Epoch 10, loss: 1.9826791286468506\n",
      "Epoch 10, loss: 1.4145495891571045\n",
      "Epoch 10, loss: 1.9092472791671753\n",
      "Epoch 10, loss: 1.9607703685760498\n",
      "Epoch 11, loss: 1.547288179397583\n",
      "Epoch 11, loss: 1.536753535270691\n",
      "Epoch 11, loss: 1.6760841608047485\n",
      "Epoch 11, loss: 1.8554946184158325\n",
      "Epoch 11, loss: 1.7732964754104614\n",
      "Epoch 11, loss: 1.7055933475494385\n",
      "Epoch 11, loss: 1.8924137353897095\n",
      "Epoch 11, loss: 1.7584866285324097\n",
      "Epoch 11, loss: 1.7719295024871826\n",
      "Epoch 11, loss: 1.7107839584350586\n",
      "Epoch 11, loss: 1.467327356338501\n",
      "Epoch 11, loss: 1.6796815395355225\n",
      "Epoch 11, loss: 1.3945672512054443\n",
      "Epoch 12, loss: 1.337476372718811\n",
      "Epoch 12, loss: 1.3417785167694092\n",
      "Epoch 12, loss: 1.3698819875717163\n",
      "Epoch 12, loss: 1.207866907119751\n",
      "Epoch 12, loss: 1.6116100549697876\n",
      "Epoch 12, loss: 1.729013442993164\n",
      "Epoch 12, loss: 1.626389980316162\n",
      "Epoch 12, loss: 1.4326412677764893\n",
      "Epoch 12, loss: 1.4718211889266968\n",
      "Epoch 12, loss: 1.3585288524627686\n",
      "Epoch 12, loss: 1.083270788192749\n",
      "Epoch 12, loss: 1.0007264614105225\n",
      "Epoch 12, loss: 1.1985927820205688\n",
      "Epoch 13, loss: 0.8801096677780151\n",
      "Epoch 13, loss: 1.2464700937271118\n",
      "Epoch 13, loss: 1.010103702545166\n",
      "Epoch 13, loss: 1.0214934349060059\n",
      "Epoch 13, loss: 1.252655267715454\n",
      "Epoch 13, loss: 1.1806570291519165\n",
      "Epoch 13, loss: 1.0777738094329834\n",
      "Epoch 13, loss: 1.0696258544921875\n",
      "Epoch 13, loss: 0.9089878797531128\n",
      "Epoch 13, loss: 1.0746475458145142\n",
      "Epoch 13, loss: 1.0796695947647095\n",
      "Epoch 13, loss: 1.20815908908844\n",
      "Epoch 13, loss: 0.978244960308075\n",
      "Epoch 14, loss: 0.9121185541152954\n",
      "Epoch 14, loss: 0.9388920068740845\n",
      "Epoch 14, loss: 0.999686062335968\n",
      "Epoch 14, loss: 0.9727963209152222\n",
      "Epoch 14, loss: 0.9658060073852539\n",
      "Epoch 14, loss: 0.9124553799629211\n",
      "Epoch 14, loss: 0.9022501707077026\n",
      "Epoch 14, loss: 0.9116397500038147\n",
      "Epoch 14, loss: 0.9269863963127136\n",
      "Epoch 14, loss: 0.8694149851799011\n",
      "Epoch 14, loss: 0.9018977880477905\n",
      "Epoch 14, loss: 0.9108132719993591\n",
      "Epoch 14, loss: 0.7125511169433594\n",
      "Epoch 15, loss: 0.8498200178146362\n",
      "Epoch 15, loss: 0.8380002975463867\n",
      "Epoch 15, loss: 0.724132239818573\n",
      "Epoch 15, loss: 0.7515095472335815\n",
      "Epoch 15, loss: 0.8089848756790161\n",
      "Epoch 15, loss: 0.7759657502174377\n",
      "Epoch 15, loss: 0.6662369966506958\n",
      "Epoch 15, loss: 0.6663382649421692\n",
      "Epoch 15, loss: 0.7234225869178772\n",
      "Epoch 15, loss: 0.7297157049179077\n",
      "Epoch 15, loss: 0.6757112741470337\n",
      "Epoch 15, loss: 0.8063044548034668\n",
      "Epoch 15, loss: 0.6962665319442749\n",
      "Epoch 16, loss: 0.6823011636734009\n",
      "Epoch 16, loss: 0.6048586368560791\n",
      "Epoch 16, loss: 0.5549030900001526\n",
      "Epoch 16, loss: 0.6932635307312012\n",
      "Epoch 16, loss: 0.568453848361969\n",
      "Epoch 16, loss: 0.601460874080658\n",
      "Epoch 16, loss: 0.650779128074646\n",
      "Epoch 16, loss: 0.6296918392181396\n",
      "Epoch 16, loss: 0.6826131343841553\n",
      "Epoch 16, loss: 0.6720531582832336\n",
      "Epoch 16, loss: 0.5626879930496216\n",
      "Epoch 16, loss: 0.586209237575531\n",
      "Epoch 16, loss: 0.48461124300956726\n",
      "Epoch 17, loss: 0.40595585107803345\n",
      "Epoch 17, loss: 0.5986233353614807\n",
      "Epoch 17, loss: 0.579694390296936\n",
      "Epoch 17, loss: 0.5830177664756775\n",
      "Epoch 17, loss: 0.6701592206954956\n",
      "Epoch 17, loss: 0.5314692258834839\n",
      "Epoch 17, loss: 0.5061689615249634\n",
      "Epoch 17, loss: 0.5546965599060059\n",
      "Epoch 17, loss: 0.4258710741996765\n",
      "Epoch 17, loss: 0.5180506110191345\n",
      "Epoch 17, loss: 0.502776563167572\n",
      "Epoch 17, loss: 0.49754539132118225\n",
      "Epoch 17, loss: 0.4891343116760254\n",
      "Epoch 18, loss: 0.4895472228527069\n",
      "Epoch 18, loss: 0.4850565791130066\n",
      "Epoch 18, loss: 0.424811452627182\n",
      "Epoch 18, loss: 0.4167751371860504\n",
      "Epoch 18, loss: 0.48926693201065063\n",
      "Epoch 18, loss: 0.4427093267440796\n",
      "Epoch 18, loss: 0.48914769291877747\n",
      "Epoch 18, loss: 0.43234601616859436\n",
      "Epoch 18, loss: 0.47016701102256775\n",
      "Epoch 18, loss: 0.4216811954975128\n",
      "Epoch 18, loss: 0.44790565967559814\n",
      "Epoch 18, loss: 0.4350186586380005\n",
      "Epoch 18, loss: 0.409567266702652\n",
      "Epoch 19, loss: 0.41845420002937317\n",
      "Epoch 19, loss: 0.41667598485946655\n",
      "Epoch 19, loss: 0.4516172409057617\n",
      "Epoch 19, loss: 0.37608346343040466\n",
      "Epoch 19, loss: 0.35580387711524963\n",
      "Epoch 19, loss: 0.41591936349868774\n",
      "Epoch 19, loss: 0.38579341769218445\n",
      "Epoch 19, loss: 0.3708047568798065\n",
      "Epoch 19, loss: 0.3697283864021301\n",
      "Epoch 19, loss: 0.36075031757354736\n",
      "Epoch 19, loss: 0.3534363806247711\n",
      "Epoch 19, loss: 0.38368937373161316\n",
      "Epoch 19, loss: 0.39476391673088074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc1e0e2833c4fea96222641f70fde54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 0/1==================\n",
      "Question: what is the blue shape?\n",
      "Prediction: \n",
      "Answer: rectangle\n",
      "Question: what color is the shape?\n",
      "Prediction: \n",
      "Answer: blue\n",
      "Question: does the image contain a rectangle?\n",
      "Prediction: \n",
      "Answer: yes\n",
      "Question: is there a triangle in the image?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there a black shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: does the image not contain a gray shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "Question: is there a red shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "Question: does the image not contain a red shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.35249989479780197 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 1/1==================\n",
      "Question: is there not a blue shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there not a blue shape in the image?\n",
      "Prediction:  yes.\n",
      "Answer: no\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.4686424434185028 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss: 0.36751917004585266\n",
      "Epoch 20, loss: 0.4088713228702545\n",
      "Epoch 20, loss: 0.40074458718299866\n",
      "Epoch 20, loss: 0.33834215998649597\n",
      "Epoch 20, loss: 0.3442702889442444\n",
      "Epoch 20, loss: 0.34751540422439575\n",
      "Epoch 20, loss: 0.31474539637565613\n",
      "Epoch 20, loss: 0.35898512601852417\n",
      "Epoch 20, loss: 0.31489697098731995\n",
      "Epoch 20, loss: 0.39767929911613464\n",
      "Epoch 20, loss: 0.33234789967536926\n",
      "Epoch 20, loss: 0.34865817427635193\n",
      "Epoch 20, loss: 0.31554001569747925\n",
      "Epoch 21, loss: 0.33060818910598755\n",
      "Epoch 21, loss: 0.3135722875595093\n",
      "Epoch 21, loss: 0.32796424627304077\n",
      "Epoch 21, loss: 0.2890769839286804\n",
      "Epoch 21, loss: 0.337995320558548\n",
      "Epoch 21, loss: 0.30882248282432556\n",
      "Epoch 21, loss: 0.3262518346309662\n",
      "Epoch 21, loss: 0.33514249324798584\n",
      "Epoch 21, loss: 0.3204061686992645\n",
      "Epoch 21, loss: 0.369016170501709\n",
      "Epoch 21, loss: 0.31523311138153076\n",
      "Epoch 21, loss: 0.3440627455711365\n",
      "Epoch 21, loss: 0.29488468170166016\n",
      "Epoch 22, loss: 0.2959635257720947\n",
      "Epoch 22, loss: 0.306323379278183\n",
      "Epoch 22, loss: 0.3174259066581726\n",
      "Epoch 22, loss: 0.2926645576953888\n",
      "Epoch 22, loss: 0.27666229009628296\n",
      "Epoch 22, loss: 0.25849199295043945\n",
      "Epoch 22, loss: 0.29585203528404236\n",
      "Epoch 22, loss: 0.3078675866127014\n",
      "Epoch 22, loss: 0.3177492916584015\n",
      "Epoch 22, loss: 0.31637606024742126\n",
      "Epoch 22, loss: 0.27795571088790894\n",
      "Epoch 22, loss: 0.35522741079330444\n",
      "Epoch 22, loss: 0.3667569160461426\n",
      "Epoch 23, loss: 0.2769044041633606\n",
      "Epoch 23, loss: 0.2848378121852875\n",
      "Epoch 23, loss: 0.31843167543411255\n",
      "Epoch 23, loss: 0.31483960151672363\n",
      "Epoch 23, loss: 0.24921177327632904\n",
      "Epoch 23, loss: 0.2788633406162262\n",
      "Epoch 23, loss: 0.25198623538017273\n",
      "Epoch 23, loss: 0.30956026911735535\n",
      "Epoch 23, loss: 0.29566851258277893\n",
      "Epoch 23, loss: 0.31494829058647156\n",
      "Epoch 23, loss: 0.2812080383300781\n",
      "Epoch 23, loss: 0.2830262780189514\n",
      "Epoch 23, loss: 0.30415600538253784\n",
      "Epoch 24, loss: 0.28699809312820435\n",
      "Epoch 24, loss: 0.24333485960960388\n",
      "Epoch 24, loss: 0.2716233730316162\n",
      "Epoch 24, loss: 0.23016437888145447\n",
      "Epoch 24, loss: 0.2630324065685272\n",
      "Epoch 24, loss: 0.3003772795200348\n",
      "Epoch 24, loss: 0.2712106704711914\n",
      "Epoch 24, loss: 0.2527596652507782\n",
      "Epoch 24, loss: 0.2758413553237915\n",
      "Epoch 24, loss: 0.2891581952571869\n",
      "Epoch 24, loss: 0.2687986493110657\n",
      "Epoch 24, loss: 0.24633358418941498\n",
      "Epoch 24, loss: 0.25716066360473633\n",
      "Epoch 25, loss: 0.24700596928596497\n",
      "Epoch 25, loss: 0.2693827748298645\n",
      "Epoch 25, loss: 0.27754417061805725\n",
      "Epoch 25, loss: 0.2622498571872711\n",
      "Epoch 25, loss: 0.31597888469696045\n",
      "Epoch 25, loss: 0.2608630061149597\n",
      "Epoch 25, loss: 0.2809864580631256\n",
      "Epoch 25, loss: 0.2492896467447281\n",
      "Epoch 25, loss: 0.25702840089797974\n",
      "Epoch 25, loss: 0.23440665006637573\n",
      "Epoch 25, loss: 0.25595828890800476\n",
      "Epoch 25, loss: 0.30287471413612366\n",
      "Epoch 25, loss: 0.27998897433280945\n",
      "Epoch 26, loss: 0.2408786416053772\n",
      "Epoch 26, loss: 0.28300178050994873\n",
      "Epoch 26, loss: 0.22963128983974457\n",
      "Epoch 26, loss: 0.2377949208021164\n",
      "Epoch 26, loss: 0.2695316672325134\n",
      "Epoch 26, loss: 0.2204083800315857\n",
      "Epoch 26, loss: 0.25625360012054443\n",
      "Epoch 26, loss: 0.2499857097864151\n",
      "Epoch 26, loss: 0.2571619749069214\n",
      "Epoch 26, loss: 0.2614503800868988\n",
      "Epoch 26, loss: 0.25966137647628784\n",
      "Epoch 26, loss: 0.2634388506412506\n",
      "Epoch 26, loss: 0.203338161110878\n",
      "Epoch 27, loss: 0.3021771311759949\n",
      "Epoch 27, loss: 0.21680700778961182\n",
      "Epoch 27, loss: 0.3062354624271393\n",
      "Epoch 27, loss: 0.24772676825523376\n",
      "Epoch 27, loss: 0.22994737327098846\n",
      "Epoch 27, loss: 0.24424445629119873\n",
      "Epoch 27, loss: 0.2100825309753418\n",
      "Epoch 27, loss: 0.24594198167324066\n",
      "Epoch 27, loss: 0.2059214860200882\n",
      "Epoch 27, loss: 0.28285709023475647\n",
      "Epoch 27, loss: 0.24621102213859558\n",
      "Epoch 27, loss: 0.20116913318634033\n",
      "Epoch 27, loss: 0.22447027266025543\n",
      "Epoch 28, loss: 0.2401890754699707\n",
      "Epoch 28, loss: 0.2533079981803894\n",
      "Epoch 28, loss: 0.1795724779367447\n",
      "Epoch 28, loss: 0.2689581513404846\n",
      "Epoch 28, loss: 0.22317270934581757\n",
      "Epoch 28, loss: 0.22916348278522491\n",
      "Epoch 28, loss: 0.21345944702625275\n",
      "Epoch 28, loss: 0.21518097817897797\n",
      "Epoch 28, loss: 0.26889896392822266\n",
      "Epoch 28, loss: 0.2504425644874573\n",
      "Epoch 28, loss: 0.22216907143592834\n",
      "Epoch 28, loss: 0.2728120684623718\n",
      "Epoch 28, loss: 0.27742940187454224\n",
      "Epoch 29, loss: 0.19821003079414368\n",
      "Epoch 29, loss: 0.22924454510211945\n",
      "Epoch 29, loss: 0.252104252576828\n",
      "Epoch 29, loss: 0.22691267728805542\n",
      "Epoch 29, loss: 0.2686573266983032\n",
      "Epoch 29, loss: 0.23253369331359863\n",
      "Epoch 29, loss: 0.2159111350774765\n",
      "Epoch 29, loss: 0.21930477023124695\n",
      "Epoch 29, loss: 0.25761348009109497\n",
      "Epoch 29, loss: 0.2303084433078766\n",
      "Epoch 29, loss: 0.21784824132919312\n",
      "Epoch 29, loss: 0.23314300179481506\n",
      "Epoch 29, loss: 0.21621569991111755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4fa3e159ea4982bba3623c0a359d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 0/1==================\n",
      "Question: what is the blue shape?\n",
      "Prediction: \n",
      "Answer: rectangle\n",
      "Question: what color is the shape?\n",
      "Prediction: \n",
      "Answer: blue\n",
      "Question: does the image contain a rectangle?\n",
      "Prediction: \n",
      "Answer: yes\n",
      "Question: is there a triangle in the image?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there a black shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: does the image not contain a gray shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "Question: is there a red shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "Question: does the image not contain a red shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.35249989479780197 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 1/1==================\n",
      "Question: is there not a blue shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there not a blue shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.47624924778938293 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, loss: 0.20277822017669678\n",
      "Epoch 30, loss: 0.2175845205783844\n",
      "Epoch 30, loss: 0.2132304310798645\n",
      "Epoch 30, loss: 0.21577408909797668\n",
      "Epoch 30, loss: 0.23608572781085968\n",
      "Epoch 30, loss: 0.27653661370277405\n",
      "Epoch 30, loss: 0.24544693529605865\n",
      "Epoch 30, loss: 0.17893856763839722\n",
      "Epoch 30, loss: 0.21290795505046844\n",
      "Epoch 30, loss: 0.18754208087921143\n",
      "Epoch 30, loss: 0.24237652122974396\n",
      "Epoch 30, loss: 0.19139525294303894\n",
      "Epoch 30, loss: 0.21208596229553223\n",
      "Epoch 31, loss: 0.2607068717479706\n",
      "Epoch 31, loss: 0.2501639127731323\n",
      "Epoch 31, loss: 0.19259653985500336\n",
      "Epoch 31, loss: 0.19958601891994476\n",
      "Epoch 31, loss: 0.1770554482936859\n",
      "Epoch 31, loss: 0.21841873228549957\n",
      "Epoch 31, loss: 0.2571340799331665\n",
      "Epoch 31, loss: 0.21250301599502563\n",
      "Epoch 31, loss: 0.2155938595533371\n",
      "Epoch 31, loss: 0.2078966349363327\n",
      "Epoch 31, loss: 0.2199760377407074\n",
      "Epoch 31, loss: 0.23606325685977936\n",
      "Epoch 31, loss: 0.2686072587966919\n",
      "Epoch 32, loss: 0.2239249050617218\n",
      "Epoch 32, loss: 0.19737933576107025\n",
      "Epoch 32, loss: 0.22462581098079681\n",
      "Epoch 32, loss: 0.19930317997932434\n",
      "Epoch 32, loss: 0.19552074372768402\n",
      "Epoch 32, loss: 0.21790610253810883\n",
      "Epoch 32, loss: 0.21522156894207\n",
      "Epoch 32, loss: 0.2458057850599289\n",
      "Epoch 32, loss: 0.18792803585529327\n",
      "Epoch 32, loss: 0.20815545320510864\n",
      "Epoch 32, loss: 0.2158781737089157\n",
      "Epoch 32, loss: 0.22755545377731323\n",
      "Epoch 32, loss: 0.22444617748260498\n",
      "Epoch 33, loss: 0.20027761161327362\n",
      "Epoch 33, loss: 0.22007544338703156\n",
      "Epoch 33, loss: 0.18006649613380432\n",
      "Epoch 33, loss: 0.24241559207439423\n",
      "Epoch 33, loss: 0.19761203229427338\n",
      "Epoch 33, loss: 0.2036900371313095\n",
      "Epoch 33, loss: 0.18693359196186066\n",
      "Epoch 33, loss: 0.21878202259540558\n",
      "Epoch 33, loss: 0.19526870548725128\n",
      "Epoch 33, loss: 0.24265027046203613\n",
      "Epoch 33, loss: 0.15428531169891357\n",
      "Epoch 33, loss: 0.21036015450954437\n",
      "Epoch 33, loss: 0.22084909677505493\n",
      "Epoch 34, loss: 0.1545514464378357\n",
      "Epoch 34, loss: 0.19145138561725616\n",
      "Epoch 34, loss: 0.1912280172109604\n",
      "Epoch 34, loss: 0.2209918051958084\n",
      "Epoch 34, loss: 0.17376570403575897\n",
      "Epoch 34, loss: 0.19930364191532135\n",
      "Epoch 34, loss: 0.19552572071552277\n",
      "Epoch 34, loss: 0.19954295456409454\n",
      "Epoch 34, loss: 0.1976149082183838\n",
      "Epoch 34, loss: 0.20848819613456726\n",
      "Epoch 34, loss: 0.2158878743648529\n",
      "Epoch 34, loss: 0.20818154513835907\n",
      "Epoch 34, loss: 0.22619488835334778\n",
      "Epoch 35, loss: 0.18389756977558136\n",
      "Epoch 35, loss: 0.18780098855495453\n",
      "Epoch 35, loss: 0.20995602011680603\n",
      "Epoch 35, loss: 0.20749621093273163\n",
      "Epoch 35, loss: 0.20345792174339294\n",
      "Epoch 35, loss: 0.19665218889713287\n",
      "Epoch 35, loss: 0.176720529794693\n",
      "Epoch 35, loss: 0.12767352163791656\n",
      "Epoch 35, loss: 0.20112797617912292\n",
      "Epoch 35, loss: 0.22026698291301727\n",
      "Epoch 35, loss: 0.1794709712266922\n",
      "Epoch 35, loss: 0.21704481542110443\n",
      "Epoch 35, loss: 0.1651456356048584\n",
      "Epoch 36, loss: 0.17486320436000824\n",
      "Epoch 36, loss: 0.19937016069889069\n",
      "Epoch 36, loss: 0.16356250643730164\n",
      "Epoch 36, loss: 0.20874564349651337\n",
      "Epoch 36, loss: 0.19815972447395325\n",
      "Epoch 36, loss: 0.19120195508003235\n",
      "Epoch 36, loss: 0.21476832032203674\n",
      "Epoch 36, loss: 0.17353516817092896\n",
      "Epoch 36, loss: 0.19349339604377747\n",
      "Epoch 36, loss: 0.20195895433425903\n",
      "Epoch 36, loss: 0.20051692426204681\n",
      "Epoch 36, loss: 0.18407435715198517\n",
      "Epoch 36, loss: 0.18736208975315094\n",
      "Epoch 37, loss: 0.2446938455104828\n",
      "Epoch 37, loss: 0.1994432657957077\n",
      "Epoch 37, loss: 0.1892215460538864\n",
      "Epoch 37, loss: 0.17114469408988953\n",
      "Epoch 37, loss: 0.15869787335395813\n",
      "Epoch 37, loss: 0.19365127384662628\n",
      "Epoch 37, loss: 0.1655605286359787\n",
      "Epoch 37, loss: 0.1446545422077179\n",
      "Epoch 37, loss: 0.1812078207731247\n",
      "Epoch 37, loss: 0.18538805842399597\n",
      "Epoch 37, loss: 0.1925169974565506\n",
      "Epoch 37, loss: 0.21019721031188965\n",
      "Epoch 37, loss: 0.20890100300312042\n",
      "Epoch 38, loss: 0.21177273988723755\n",
      "Epoch 38, loss: 0.17210254073143005\n",
      "Epoch 38, loss: 0.17523179948329926\n",
      "Epoch 38, loss: 0.15843607485294342\n",
      "Epoch 38, loss: 0.18554933369159698\n",
      "Epoch 38, loss: 0.16444233059883118\n",
      "Epoch 38, loss: 0.18497154116630554\n",
      "Epoch 38, loss: 0.17613203823566437\n",
      "Epoch 38, loss: 0.21021071076393127\n",
      "Epoch 38, loss: 0.19886861741542816\n",
      "Epoch 38, loss: 0.1916370987892151\n",
      "Epoch 38, loss: 0.1742396354675293\n",
      "Epoch 38, loss: 0.1947198510169983\n",
      "Epoch 39, loss: 0.1674841195344925\n",
      "Epoch 39, loss: 0.16928549110889435\n",
      "Epoch 39, loss: 0.1667945384979248\n",
      "Epoch 39, loss: 0.17662164568901062\n",
      "Epoch 39, loss: 0.1846618950366974\n",
      "Epoch 39, loss: 0.17924363911151886\n",
      "Epoch 39, loss: 0.18336930871009827\n",
      "Epoch 39, loss: 0.17092883586883545\n",
      "Epoch 39, loss: 0.19098696112632751\n",
      "Epoch 39, loss: 0.1897096037864685\n",
      "Epoch 39, loss: 0.2080857902765274\n",
      "Epoch 39, loss: 0.1865856945514679\n",
      "Epoch 39, loss: 0.21976731717586517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7dde1502af429b88d48ef16d093318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 0/1==================\n",
      "Question: what is the blue shape?\n",
      "Prediction: \n",
      "Answer: rectangle\n",
      "Question: what color is the shape?\n",
      "Prediction: \n",
      "Answer: blue\n",
      "Question: does the image contain a rectangle?\n",
      "Prediction: \n",
      "Answer: yes\n",
      "Question: is there a triangle in the image?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there a black shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: does the image not contain a gray shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "Question: is there a red shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "Question: does the image not contain a red shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.35249989479780197 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 1/1==================\n",
      "Question: is there not a blue shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there not a blue shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.47624924778938293 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, loss: 0.15496239066123962\n",
      "Epoch 40, loss: 0.16191862523555756\n",
      "Epoch 40, loss: 0.17429131269454956\n",
      "Epoch 40, loss: 0.16567400097846985\n",
      "Epoch 40, loss: 0.18732210993766785\n",
      "Epoch 40, loss: 0.15923823416233063\n",
      "Epoch 40, loss: 0.20020894706249237\n",
      "Epoch 40, loss: 0.1944759041070938\n",
      "Epoch 40, loss: 0.207807719707489\n",
      "Epoch 40, loss: 0.17790473997592926\n",
      "Epoch 40, loss: 0.17579931020736694\n",
      "Epoch 40, loss: 0.2100260704755783\n",
      "Epoch 40, loss: 0.17752327024936676\n",
      "Epoch 41, loss: 0.17182159423828125\n",
      "Epoch 41, loss: 0.15856356918811798\n",
      "Epoch 41, loss: 0.1833084523677826\n",
      "Epoch 41, loss: 0.15243154764175415\n",
      "Epoch 41, loss: 0.18496738374233246\n",
      "Epoch 41, loss: 0.15275470912456512\n",
      "Epoch 41, loss: 0.1982761174440384\n",
      "Epoch 41, loss: 0.1990821361541748\n",
      "Epoch 41, loss: 0.1818024218082428\n",
      "Epoch 41, loss: 0.18938814103603363\n",
      "Epoch 41, loss: 0.19338394701480865\n",
      "Epoch 41, loss: 0.18857702612876892\n",
      "Epoch 41, loss: 0.20022958517074585\n",
      "Epoch 42, loss: 0.23392082750797272\n",
      "Epoch 42, loss: 0.16213274002075195\n",
      "Epoch 42, loss: 0.17174622416496277\n",
      "Epoch 42, loss: 0.16363811492919922\n",
      "Epoch 42, loss: 0.1813475787639618\n",
      "Epoch 42, loss: 0.17147290706634521\n",
      "Epoch 42, loss: 0.17049245536327362\n",
      "Epoch 42, loss: 0.17723466455936432\n",
      "Epoch 42, loss: 0.17788146436214447\n",
      "Epoch 42, loss: 0.15922757983207703\n",
      "Epoch 42, loss: 0.19037635624408722\n",
      "Epoch 42, loss: 0.18816880881786346\n",
      "Epoch 42, loss: 0.1833627074956894\n",
      "Epoch 43, loss: 0.16558347642421722\n",
      "Epoch 43, loss: 0.18170066177845\n",
      "Epoch 43, loss: 0.17931625247001648\n",
      "Epoch 43, loss: 0.19801399111747742\n",
      "Epoch 43, loss: 0.16230887174606323\n",
      "Epoch 43, loss: 0.1657048761844635\n",
      "Epoch 43, loss: 0.1715129315853119\n",
      "Epoch 43, loss: 0.15035860240459442\n",
      "Epoch 43, loss: 0.19674761593341827\n",
      "Epoch 43, loss: 0.17850200831890106\n",
      "Epoch 43, loss: 0.17470809817314148\n",
      "Epoch 43, loss: 0.1776505559682846\n",
      "Epoch 43, loss: 0.2073024958372116\n",
      "Epoch 44, loss: 0.18810635805130005\n",
      "Epoch 44, loss: 0.15512460470199585\n",
      "Epoch 44, loss: 0.13458727300167084\n",
      "Epoch 44, loss: 0.13803765177726746\n",
      "Epoch 44, loss: 0.18287625908851624\n",
      "Epoch 44, loss: 0.19635699689388275\n",
      "Epoch 44, loss: 0.1838027387857437\n",
      "Epoch 44, loss: 0.1777982860803604\n",
      "Epoch 44, loss: 0.17961080372333527\n",
      "Epoch 44, loss: 0.21060648560523987\n",
      "Epoch 44, loss: 0.23042236268520355\n",
      "Epoch 44, loss: 0.16172516345977783\n",
      "Epoch 44, loss: 0.22078096866607666\n",
      "Epoch 45, loss: 0.17068737745285034\n",
      "Epoch 45, loss: 0.19530539214611053\n",
      "Epoch 45, loss: 0.1526491940021515\n",
      "Epoch 45, loss: 0.18973900377750397\n",
      "Epoch 45, loss: 0.19676841795444489\n",
      "Epoch 45, loss: 0.20626136660575867\n",
      "Epoch 45, loss: 0.14998003840446472\n",
      "Epoch 45, loss: 0.17339807748794556\n",
      "Epoch 45, loss: 0.18825122714042664\n",
      "Epoch 45, loss: 0.16676266491413116\n",
      "Epoch 45, loss: 0.16476786136627197\n",
      "Epoch 45, loss: 0.19855129718780518\n",
      "Epoch 45, loss: 0.17623266577720642\n",
      "Epoch 46, loss: 0.1712641566991806\n",
      "Epoch 46, loss: 0.18736128509044647\n",
      "Epoch 46, loss: 0.15503035485744476\n",
      "Epoch 46, loss: 0.15764810144901276\n",
      "Epoch 46, loss: 0.18293792009353638\n",
      "Epoch 46, loss: 0.1789783388376236\n",
      "Epoch 46, loss: 0.15443618595600128\n",
      "Epoch 46, loss: 0.20500607788562775\n",
      "Epoch 46, loss: 0.1649457961320877\n",
      "Epoch 46, loss: 0.18012018501758575\n",
      "Epoch 46, loss: 0.16520027816295624\n",
      "Epoch 46, loss: 0.15753677487373352\n",
      "Epoch 46, loss: 0.17862723767757416\n",
      "Epoch 47, loss: 0.17993102967739105\n",
      "Epoch 47, loss: 0.15153877437114716\n",
      "Epoch 47, loss: 0.18078455328941345\n",
      "Epoch 47, loss: 0.19042664766311646\n",
      "Epoch 47, loss: 0.1558636873960495\n",
      "Epoch 47, loss: 0.1907101422548294\n",
      "Epoch 47, loss: 0.16427750885486603\n",
      "Epoch 47, loss: 0.15730753540992737\n",
      "Epoch 47, loss: 0.19644078612327576\n",
      "Epoch 47, loss: 0.17378564178943634\n",
      "Epoch 47, loss: 0.1405765414237976\n",
      "Epoch 47, loss: 0.17996536195278168\n",
      "Epoch 47, loss: 0.21735522150993347\n",
      "Epoch 48, loss: 0.16610190272331238\n",
      "Epoch 48, loss: 0.15786804258823395\n",
      "Epoch 48, loss: 0.14783497154712677\n",
      "Epoch 48, loss: 0.16404062509536743\n",
      "Epoch 48, loss: 0.15352649986743927\n",
      "Epoch 48, loss: 0.18260595202445984\n",
      "Epoch 48, loss: 0.1497698724269867\n",
      "Epoch 48, loss: 0.19626395404338837\n",
      "Epoch 48, loss: 0.18663610517978668\n",
      "Epoch 48, loss: 0.17214803397655487\n",
      "Epoch 48, loss: 0.16840775310993195\n",
      "Epoch 48, loss: 0.18350674211978912\n",
      "Epoch 48, loss: 0.20888109505176544\n",
      "Epoch 49, loss: 0.16142228245735168\n",
      "Epoch 49, loss: 0.14569824934005737\n",
      "Epoch 49, loss: 0.17125444114208221\n",
      "Epoch 49, loss: 0.15908437967300415\n",
      "Epoch 49, loss: 0.16781401634216309\n",
      "Epoch 49, loss: 0.16784872114658356\n",
      "Epoch 49, loss: 0.19980263710021973\n",
      "Epoch 49, loss: 0.15517136454582214\n",
      "Epoch 49, loss: 0.17094464600086212\n",
      "Epoch 49, loss: 0.17299965023994446\n",
      "Epoch 49, loss: 0.17756487429141998\n",
      "Epoch 49, loss: 0.1473097950220108\n",
      "Epoch 49, loss: 0.19640064239501953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed4e15811d34e43a21b10d714e22201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 0/1==================\n",
      "Question: what is the blue shape?\n",
      "Prediction: \n",
      "Answer: rectangle\n",
      "Question: what color is the shape?\n",
      "Prediction: \n",
      "Answer: blue\n",
      "Question: does the image contain a rectangle?\n",
      "Prediction: \n",
      "Answer: yes\n",
      "Question: is there a triangle in the image?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there a black shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: does the image not contain a gray shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "Question: is there a red shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "Question: does the image not contain a red shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.35249989479780197 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 1/1==================\n",
      "Question: is there not a blue shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there not a blue shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.47624924778938293 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=[0],\n",
    "        max_epochs=50,\n",
    "        accumulate_grad_batches=config.get(\"accumulate_grad_batches\"),\n",
    "        check_val_every_n_epoch=10,\n",
    "        gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
    "        precision=\"16-mixed\",\n",
    "        limit_val_batches=5,\n",
    "        num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(model_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does the image not contain a gray shape?\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD26iiiszcKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArkvEHxH8P+GdVbTtRkuFuFRXIjhLDB6c11tfN/xn/5KFN/17RfyNe9kOX0cfi/Y1r2s3pptYxrTcI3R6f/AMLn8If89rz/AMBzR/wufwh/z2vP/Ac1830V9x/qjl/eX3/8A4/rUz6Q/wCFz+EP+e15/wCA5rubC9h1LT7e9tyTDcRrIhYYO0jI4r42r638If8AImaL/wBeUX/oAr5niLJcNl1KE6F7ybWrv0v2OihWlUbTNqiiivjzqCvm/wCM/wDyUKb/AK9ov5GvpCvE/ib4D8R+IPGMl/pmn+fbGCNA/movIHPBNfT8L16VHHOdWSiuV6t27HPiYtwsjxqiu0/4VP4z/wCgR/5Hj/8AiqP+FT+M/wDoEf8AkeP/AOKr9M/tTA/8/o/+BI8/2c+xxdfW/hD/AJEzRf8Aryi/9AFfPn/Cp/Gf/QI/8jx//FV9E+G7Saw8M6XaXKbJ4LWOORc5wwUAivjOLcXh69CkqM1JpvZp9DqwsZRbuj//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAABJElEQVR4Ae2aMQ6CQBBFAQk2Bqw00RjPY2Fv423svBUJHsXCSmy0kYglE2LzljEk325M5s/Oe9BsiF+3azTmXzLmw3/PrgX+bVAGZAAS0CMEAeJ2GcAIYYAMQIC4XQYwQhggAxAgbpcBjBAGyAAEiNtlACOEATIAAeJ2GcAIYYAMQIC4XQYwQhggAxAgbpcBjBAGyAAEiNtTnNAJKC/Tsso6fwUq5kVzPDyLvDF5oReostN5ZmYEKbeb9373KnIbpnfAEvGuZcCbuJ0nA5aIdy0D3sTtPBmwRLxrGfAmbufJgCXiXcuAN3E7TwYsEe9aBryJ23kyYIl414GvVdrbm/b+Y4gl1qt32nfYOOzX63Wd3B/xEAukk2i56Nkh8AJDHP135gflrB34+KyJkgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image\n",
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "example = train_dataset[5]\n",
    "image = example[0]\n",
    "\n",
    "text_inputs = processor.tokenizer(\n",
    "    example[1][\"question\"], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "question = example[1]['question']\n",
    "\n",
    "text = f\"Question: {question} Answer:\"\n",
    "print(question)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, text=text, return_tensors=\"pt\").to('cuda', torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " yes.\n"
     ]
    }
   ],
   "source": [
    "# prepare image for the model\n",
    "import torch\n",
    "inputs = processor(images=image, text=text, return_tensors=\"pt\").to('cuda', torch.float32).to('cuda', torch.float16)\n",
    "pixel_values = inputs.pixel_values\n",
    "\n",
    "model.to('cuda')\n",
    "# generated_ids = model.generate(pixel_values, max_length=25)\n",
    "generated_ids = model.generate(**inputs)\n",
    "generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef336002fd74dbea1f3d27ca25f131b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 0/1==================\n",
      "Question: what is the blue shape?\n",
      "Prediction: \n",
      "Answer: rectangle\n",
      "Question: what color is the shape?\n",
      "Prediction: \n",
      "Answer: blue\n",
      "Question: does the image contain a rectangle?\n",
      "Prediction: \n",
      "Answer: yes\n",
      "Question: is there a triangle in the image?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there a black shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: does the image not contain a gray shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "Question: is there a red shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "Question: does the image not contain a red shape?\n",
      "Prediction:  yes.\n",
      "Answer: yes\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.35249989479780197 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Dataset batch: 1/1==================\n",
      "Question: is there not a blue shape?\n",
      "Prediction: \n",
      "Answer: no\n",
      "Question: is there not a blue shape in the image?\n",
      "Prediction:  no.\n",
      "Answer: no\n",
      "accuracy: 0.0\n",
      "f1score: 0.0\n",
      "WUP Measure: 0.0 \n",
      "\n",
      "\n",
      "val_bertscore_f1: 0.47624924778938293 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          f1score          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     val_bertscore_f1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.41437458992004395    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        wup_measure        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         f1score         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    val_bertscore_f1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.41437458992004395   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       wup_measure       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.0,\n",
       "  'f1score': 0.0,\n",
       "  'wup_measure': 0.0,\n",
       "  'val_bertscore_f1': 0.41437458992004395}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "questllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
